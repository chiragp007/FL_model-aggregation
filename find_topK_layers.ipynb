{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "028d88d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn import preprocessing\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from folktables import ACSDataSource, ACSEmployment,ACSIncome\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f87d866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 14 : input shape\n",
    "        self.layer1 = nn.Linear(14, 512)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.layer2 = nn.Linear(512, 256)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(256, 60)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.output = nn.Linear(60, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.layer1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.act2(self.layer2(x))\n",
    "        x = self.act3(self.layer3(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf7ee81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eba37bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepNet(\n",
       "  (layer1): Linear(in_features=14, out_features=512, bias=True)\n",
       "  (act1): ReLU()\n",
       "  (dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (layer2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (act2): ReLU()\n",
       "  (layer3): Linear(in_features=256, out_features=60, bias=True)\n",
       "  (act3): ReLU()\n",
       "  (output): Linear(in_features=60, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_of_model='WW_WM_BW.pth'\n",
    "model = DeepNet()\n",
    "# model = Deep_wide_Net()\n",
    "model.load_state_dict(torch.load(name_of_model))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84f74a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caff4ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e64c4aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['layer1.weight', 'layer1.bias', 'layer2.weight', 'layer2.bias', 'layer3.weight', 'layer3.bias', 'output.weight', 'output.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict().keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3093604a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-2 layers:\n",
      "layer1.weight\n",
      "layer2.weight\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e389502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1ffb0e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([152, 150])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = model.state_dict()\n",
    "\n",
    "# Convert the state dictionary to a tensor\n",
    "tensor = torch.cat([value.flatten() for value in state_dict.values()])\n",
    "\n",
    "# Apply the topk function to the tensor\n",
    "_, top_i = torch.topk(tensor, k=2)\n",
    "\n",
    "top_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb570467",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = ['layer1.weight', 'layer1.bias', 'layer2.weight', 'layer2.bias', 'layer3.weight', 'layer3.bias']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "14ab5766",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = []\n",
    "k=2\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        weights.append(torch.norm(param.data))\n",
    "\n",
    "# Convert the weights to a tensor\n",
    "weights_tensor = torch.stack(weights)\n",
    "\n",
    "# Find the indices of the top-k layers\n",
    "topk_indices = torch.topk(weights_tensor, k).indices\n",
    "\n",
    "topk_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0f6ad411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-2 layers:\n",
      "layer1.weight\n",
      "layer2.weight\n"
     ]
    }
   ],
   "source": [
    "# Get the top-k layer names\n",
    "layer_names = list(model.state_dict().keys())\n",
    "topk_layers = [layer_names[idx] for idx in topk_indices]\n",
    "\n",
    "print(\"Top-{} layers:\".format(k))\n",
    "for layer in topk_layers:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c3b6337f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3aac5ca0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer1.weight': tensor([[-0.1236,  0.0936, -0.0858,  ..., -0.2022,  0.2071,  0.2143],\n",
      "        [-0.0173, -0.0282,  0.0289,  ..., -0.0473,  0.0984, -0.1676],\n",
      "        [ 0.2257, -0.0810, -0.0682,  ..., -0.0027, -0.1340, -0.0711],\n",
      "        ...,\n",
      "        [-0.0892, -0.2357,  0.0203,  ...,  0.2679, -0.0388, -0.2460],\n",
      "        [ 0.2170,  0.2365,  0.2169,  ..., -0.1546,  0.0313,  0.2786],\n",
      "        [-0.0207, -0.1458, -0.1536,  ...,  0.0709, -0.0735, -0.1318]]), 'layer1.bias': tensor([-0.0322,  0.0426, -0.0603,  0.0798,  0.1138,  0.1408,  0.0317,  0.2289,\n",
      "         0.1325, -0.1165, -0.1265,  0.2285, -0.0939,  0.1958,  0.2569,  0.1675,\n",
      "        -0.2616,  0.1116,  0.1401, -0.0685, -0.1891, -0.1634, -0.1235,  0.0884,\n",
      "        -0.2367,  0.2376, -0.0763, -0.0003,  0.1408, -0.0229,  0.1229, -0.1721,\n",
      "         0.0450, -0.2093,  0.0882, -0.2293, -0.2588,  0.1078, -0.0765,  0.0842,\n",
      "        -0.0346, -0.0134, -0.2554,  0.0831, -0.1555,  0.0582,  0.1946, -0.2204,\n",
      "         0.2441,  0.1677, -0.0461, -0.1893,  0.2440,  0.1668, -0.0349, -0.1506,\n",
      "        -0.1688,  0.2263,  0.0252, -0.1341,  0.1226,  0.0148, -0.2670, -0.2387,\n",
      "        -0.1646,  0.0938,  0.2166, -0.1961,  0.2032,  0.2083, -0.0538, -0.1734,\n",
      "        -0.0966,  0.1707,  0.2654, -0.1752,  0.1697,  0.0705,  0.0117, -0.1214,\n",
      "        -0.0225,  0.2655,  0.0326, -0.2243,  0.0494,  0.0262,  0.1043, -0.2016,\n",
      "        -0.1868,  0.2294,  0.1924, -0.0286,  0.1204,  0.0552,  0.1580,  0.2101,\n",
      "         0.0064,  0.1496,  0.0149, -0.2476,  0.2136, -0.2267, -0.1353, -0.2492,\n",
      "        -0.0971,  0.0536,  0.0151, -0.1011, -0.1989,  0.1396, -0.0581, -0.0835,\n",
      "        -0.0924,  0.0628,  0.0724, -0.1092,  0.1702, -0.1673, -0.1401, -0.0940,\n",
      "         0.1129,  0.2617, -0.1878,  0.0058, -0.0888,  0.1451, -0.1095, -0.1658,\n",
      "        -0.0124,  0.0627, -0.1805, -0.2139,  0.1665, -0.2399,  0.1778,  0.0173,\n",
      "         0.2214, -0.2617,  0.1081, -0.1959,  0.0678, -0.0350,  0.1809, -0.1450,\n",
      "         0.2169, -0.1114,  0.1557,  0.0868, -0.0219, -0.0083, -0.1890, -0.0412,\n",
      "        -0.2220,  0.1934,  0.2318, -0.0247, -0.1509, -0.0488, -0.0465,  0.0737,\n",
      "        -0.2061, -0.2349,  0.2161,  0.2344,  0.2316, -0.1617,  0.0875,  0.0097,\n",
      "        -0.0420,  0.0644, -0.1184,  0.0654, -0.1385,  0.0454,  0.2524,  0.1664,\n",
      "         0.1929, -0.1204,  0.2308, -0.1499,  0.0881,  0.0181,  0.2450, -0.1845,\n",
      "         0.1118, -0.0929,  0.0865,  0.2135, -0.0189, -0.0089,  0.1641,  0.0661,\n",
      "         0.1976, -0.1441,  0.0790,  0.2366,  0.0260, -0.0965, -0.1012, -0.1548,\n",
      "         0.1602, -0.0468, -0.2533,  0.1919,  0.1327,  0.1548, -0.1613,  0.1136,\n",
      "         0.1652, -0.1754,  0.1503, -0.0373, -0.2608,  0.1419, -0.2441,  0.2094,\n",
      "        -0.2494,  0.0223, -0.2322,  0.0267, -0.1226, -0.0819,  0.0992, -0.0039,\n",
      "         0.1870, -0.0248,  0.2247,  0.0420, -0.1182, -0.1147,  0.0921, -0.0033,\n",
      "         0.2048,  0.1877, -0.1732, -0.0861,  0.2154,  0.0813, -0.0482, -0.1471,\n",
      "         0.0729,  0.1672, -0.2414,  0.1081, -0.0761, -0.1497, -0.0425,  0.0763,\n",
      "         0.0946, -0.1367,  0.0379, -0.0749, -0.2108,  0.0960,  0.0245,  0.2244,\n",
      "         0.1602, -0.2316, -0.0304, -0.1809, -0.0896,  0.2048,  0.2831,  0.2165,\n",
      "        -0.2307, -0.1157, -0.0104,  0.0336,  0.1026,  0.2040,  0.0713, -0.2639,\n",
      "         0.0778,  0.0500,  0.1923,  0.1277,  0.1815, -0.2308,  0.1551, -0.2286,\n",
      "        -0.2252, -0.0512,  0.2110,  0.0355, -0.1942,  0.1886, -0.1394,  0.0509,\n",
      "         0.1202, -0.1873, -0.0009, -0.0283,  0.2121,  0.0804,  0.1885,  0.2071,\n",
      "        -0.1146,  0.1334,  0.0909,  0.1458,  0.0371, -0.1957,  0.2245, -0.2641,\n",
      "        -0.0151, -0.0276, -0.0836, -0.1191, -0.0810,  0.1114, -0.1471, -0.0285,\n",
      "        -0.0704,  0.1866,  0.2525,  0.0854,  0.1541, -0.1246, -0.2074,  0.1898,\n",
      "         0.2544,  0.1057,  0.0266, -0.2380,  0.2070,  0.0359,  0.0576,  0.1031,\n",
      "         0.1448, -0.2236, -0.0662,  0.1450, -0.1213, -0.1980, -0.0199,  0.1476,\n",
      "         0.1931, -0.1353,  0.1945, -0.0050,  0.0417, -0.0790, -0.1385,  0.1613,\n",
      "         0.1442,  0.0873, -0.1752,  0.1793,  0.2524, -0.2422,  0.1832,  0.2125,\n",
      "         0.0878, -0.2427, -0.1157, -0.1772,  0.1735,  0.0131,  0.0559, -0.0500,\n",
      "        -0.1939, -0.1549,  0.1681,  0.2576,  0.0758,  0.0899,  0.0342, -0.0172,\n",
      "        -0.1564, -0.2578,  0.1180, -0.2498, -0.0539, -0.1182, -0.0336, -0.1141,\n",
      "         0.0446, -0.1486,  0.1746,  0.0762, -0.1405,  0.0448, -0.2609,  0.0096,\n",
      "        -0.0782,  0.2262,  0.2258, -0.0248,  0.0938, -0.2441, -0.0882,  0.0792,\n",
      "        -0.1055, -0.1155,  0.0341,  0.1175,  0.0215, -0.0857, -0.1695, -0.1577,\n",
      "        -0.1969,  0.1435, -0.2649,  0.1795, -0.1148,  0.2169,  0.0949, -0.2064,\n",
      "         0.0621, -0.1601,  0.2444, -0.0065,  0.1467,  0.0220,  0.0661,  0.1205,\n",
      "         0.0683, -0.1975,  0.0651,  0.2035,  0.1648, -0.2009, -0.2092, -0.2035,\n",
      "         0.0442,  0.2364, -0.2322, -0.1091, -0.1303, -0.0804, -0.1521,  0.0437,\n",
      "        -0.0293, -0.0676,  0.2063, -0.2415, -0.0775,  0.0658,  0.1934,  0.1241,\n",
      "         0.2322,  0.0168, -0.0104,  0.0872,  0.0879, -0.1017, -0.0718, -0.1307,\n",
      "         0.2594, -0.2004,  0.1750,  0.0769,  0.2043,  0.0724, -0.2261,  0.0856,\n",
      "        -0.1057, -0.2325,  0.1403,  0.0057,  0.1419,  0.0259,  0.1827, -0.0589,\n",
      "         0.0746, -0.0092, -0.0078, -0.1230,  0.1779,  0.1347, -0.0604,  0.1400,\n",
      "        -0.0195,  0.1195, -0.2178,  0.2222,  0.0282, -0.0979,  0.0141, -0.0208,\n",
      "         0.0783,  0.0834,  0.1010,  0.1194,  0.0306,  0.1227, -0.0238, -0.0877,\n",
      "        -0.1093,  0.0120,  0.2259,  0.1914, -0.1404,  0.1296, -0.1403,  0.1636,\n",
      "        -0.2438,  0.1688,  0.2359, -0.0039,  0.1959, -0.2448,  0.1091, -0.0898,\n",
      "        -0.0822, -0.1436, -0.0462,  0.1166, -0.1012,  0.2074,  0.0394,  0.0921]), 'layer2.weight': tensor([[ 4.1278e-02, -6.7849e-03, -4.5960e-02,  ...,  6.2805e-05,\n",
      "         -2.6595e-02, -1.8976e-02],\n",
      "        [ 1.7838e-03, -2.4043e-02,  7.7809e-04,  ..., -7.5658e-02,\n",
      "          5.3687e-02, -8.9672e-03],\n",
      "        [ 1.0132e-02, -3.3095e-02, -2.9559e-02,  ..., -4.8992e-02,\n",
      "         -7.1659e-03,  2.1242e-02],\n",
      "        ...,\n",
      "        [-1.7378e-02, -8.9730e-03, -1.6638e-02,  ..., -2.5265e-02,\n",
      "          2.3593e-02,  1.8103e-02],\n",
      "        [ 3.5799e-02,  8.1830e-02,  2.2687e-03,  ...,  6.2357e-02,\n",
      "          1.8346e-02,  4.6302e-02],\n",
      "        [ 8.7989e-02,  4.6054e-02,  4.5712e-02,  ...,  2.1118e-02,\n",
      "         -5.3984e-02,  1.1680e-01]]), 'layer2.bias': tensor([ 0.0384,  0.0524,  0.0343, -0.0506,  0.0003, -0.0071, -0.0294, -0.0185,\n",
      "         0.0118,  0.0057, -0.0228, -0.0090,  0.0057,  0.0404, -0.0217,  0.0036,\n",
      "        -0.0181,  0.0074, -0.0317, -0.0342,  0.0071, -0.0288, -0.0408,  0.0442,\n",
      "         0.0342, -0.0332, -0.0362,  0.0176, -0.0375,  0.0318,  0.0404,  0.0458,\n",
      "         0.0078,  0.0040,  0.0200, -0.0366,  0.0267, -0.0022,  0.0354, -0.0474,\n",
      "        -0.0166, -0.0006, -0.0007,  0.0400, -0.0372, -0.0399, -0.0033, -0.0008,\n",
      "         0.0100, -0.0250,  0.0383,  0.0199,  0.0128,  0.0305,  0.0343, -0.0221,\n",
      "         0.0687,  0.0022,  0.0105,  0.0151,  0.0002, -0.0363,  0.0017,  0.0028,\n",
      "         0.0230,  0.0226, -0.0056, -0.0060, -0.0110, -0.0195, -0.0237,  0.0310,\n",
      "         0.0229,  0.0102, -0.0455,  0.0325,  0.0163,  0.0451,  0.0147, -0.0333,\n",
      "        -0.0341, -0.0206, -0.0069,  0.0169,  0.0133, -0.0024, -0.0069, -0.0051,\n",
      "        -0.0018, -0.0373,  0.0120,  0.0156,  0.0120, -0.0171, -0.0177,  0.0141,\n",
      "        -0.0035, -0.0330, -0.0130, -0.0467, -0.0018,  0.0134, -0.0195, -0.0312,\n",
      "         0.0419,  0.0307,  0.0108, -0.0144,  0.0031,  0.0107, -0.0223,  0.0073,\n",
      "         0.0363, -0.0120, -0.0274, -0.0069,  0.0219,  0.0114, -0.0360,  0.0247,\n",
      "        -0.0016,  0.0057, -0.0445, -0.0320, -0.0266,  0.0085,  0.0428,  0.0379,\n",
      "        -0.0180,  0.0529,  0.0405, -0.0164,  0.0095, -0.0098,  0.0112,  0.0060,\n",
      "         0.0351, -0.0354,  0.0060, -0.0238, -0.0246,  0.0400,  0.0024,  0.0903,\n",
      "         0.0025,  0.0171, -0.0017, -0.0331, -0.0256,  0.0092, -0.0064, -0.0089,\n",
      "        -0.0344,  0.0494, -0.0250, -0.0384, -0.0258, -0.0120, -0.0347,  0.0508,\n",
      "        -0.0008, -0.0334, -0.0415,  0.0257,  0.0609,  0.0077, -0.0350, -0.0118,\n",
      "        -0.0241,  0.0029,  0.0233, -0.0546, -0.0086, -0.0486, -0.0328,  0.0228,\n",
      "        -0.0439, -0.0425, -0.0320,  0.0123, -0.0224,  0.0212, -0.0295,  0.0227,\n",
      "         0.0373,  0.0509, -0.0486,  0.0102,  0.0256,  0.0283, -0.0049,  0.0052,\n",
      "        -0.0157,  0.0483,  0.0189,  0.0068, -0.0114,  0.0213, -0.0225,  0.0361,\n",
      "        -0.0154, -0.0002,  0.0180, -0.0240,  0.0241,  0.0006,  0.0318, -0.0221,\n",
      "        -0.0064, -0.0498,  0.0070,  0.0372, -0.0281, -0.0068, -0.0252, -0.0090,\n",
      "         0.0113,  0.0234, -0.0158,  0.0324, -0.0249, -0.0172, -0.0205, -0.0013,\n",
      "         0.0095, -0.0057, -0.0430, -0.0238, -0.0108, -0.0365, -0.0168,  0.0380,\n",
      "        -0.0142,  0.0281, -0.0181,  0.0036,  0.0233,  0.0110,  0.0047,  0.0148,\n",
      "        -0.0202,  0.0722, -0.0015, -0.0202,  0.0105, -0.0281, -0.0308, -0.0169,\n",
      "         0.0263,  0.0244, -0.0248,  0.0092,  0.0101,  0.0149,  0.0076, -0.0055]), 'layer3.weight': tensor([[ 5.4633e-02,  8.1261e-03, -3.0832e-02,  ...,  5.4763e-02,\n",
      "         -3.9070e-02, -4.7520e-02],\n",
      "        [ 7.2382e-02, -4.7307e-02, -2.3797e-02,  ...,  3.9055e-03,\n",
      "         -1.5235e-02, -1.7146e-02],\n",
      "        [-1.7924e-02,  4.6757e-04, -4.0349e-02,  ...,  5.7521e-02,\n",
      "          9.0531e-02, -2.5051e-03],\n",
      "        ...,\n",
      "        [ 1.4053e-02, -4.3309e-02,  3.2839e-05,  ..., -2.4532e-02,\n",
      "         -2.0915e-02,  6.3625e-02],\n",
      "        [-5.1204e-03,  4.1185e-02,  1.7763e-02,  ...,  2.1898e-03,\n",
      "         -7.2193e-02,  1.9890e-02],\n",
      "        [-5.4119e-02,  2.7216e-02, -4.5889e-02,  ...,  1.9468e-03,\n",
      "          1.6108e-02,  3.3428e-02]]), 'layer3.bias': tensor([ 0.0218,  0.0122, -0.0090,  0.0192,  0.0073, -0.0146, -0.0172, -0.0161,\n",
      "         0.0034, -0.0175, -0.0405,  0.0299, -0.0603, -0.0260,  0.0148, -0.0506,\n",
      "         0.0101,  0.0233,  0.0611,  0.0053,  0.0120,  0.0282, -0.0101, -0.0045,\n",
      "         0.0508,  0.0130, -0.0003, -0.0131, -0.0401,  0.0463, -0.0210,  0.0293,\n",
      "        -0.0256,  0.0346,  0.0168, -0.0242, -0.0049, -0.0485,  0.0420,  0.0150,\n",
      "         0.0399, -0.0609, -0.0609,  0.0046,  0.0419, -0.0323, -0.0594,  0.0583,\n",
      "        -0.0254, -0.0278,  0.0016, -0.0256, -0.0305,  0.0366, -0.0453,  0.0189,\n",
      "        -0.0292,  0.0077,  0.0030, -0.0285]), 'output.weight': tensor([[ 0.0554, -0.0423, -0.1156,  0.0730, -0.0532,  0.0089, -0.0901, -0.1038,\n",
      "         -0.1392,  0.0981,  0.0516,  0.1187, -0.0476, -0.1402,  0.0835,  0.0997,\n",
      "         -0.1758,  0.1161,  0.1730,  0.0904, -0.0909,  0.0716, -0.0481, -0.0731,\n",
      "         -0.1037, -0.0566, -0.0789,  0.0637,  0.0840, -0.0526,  0.0498,  0.0710,\n",
      "         -0.0173,  0.0521, -0.0801,  0.1083, -0.1271,  0.0110,  0.1764, -0.1537,\n",
      "         -0.1162, -0.0945, -0.1474,  0.1394,  0.0944,  0.0190,  0.0964, -0.1173,\n",
      "         -0.1240,  0.1212,  0.1095, -0.0452,  0.0376, -0.1081, -0.0215, -0.1443,\n",
      "          0.0689, -0.1461,  0.1446, -0.0005]]), 'output.bias': tensor([-0.0053])}\n"
     ]
    }
   ],
   "source": [
    "alpha = {}\n",
    "for name, _ in model.named_parameters():\n",
    "    alpha[name] = model.state_dict()[name]\n",
    "\n",
    "print(alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "18ae736d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1236,  0.0936, -0.0858,  ..., -0.2022,  0.2071,  0.2143],\n",
       "        [-0.0173, -0.0282,  0.0289,  ..., -0.0473,  0.0984, -0.1676],\n",
       "        [ 0.2257, -0.0810, -0.0682,  ..., -0.0027, -0.1340, -0.0711],\n",
       "        ...,\n",
       "        [-0.0892, -0.2357,  0.0203,  ...,  0.2679, -0.0388, -0.2460],\n",
       "        [ 0.2170,  0.2365,  0.2169,  ..., -0.1546,  0.0313,  0.2786],\n",
       "        [-0.0207, -0.1458, -0.1536,  ...,  0.0709, -0.0735, -0.1318]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha['layer1.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d42d13a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a06087e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params_name = [name for name in model.state_dict().keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1adf70f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['layer1.weight',\n",
       " 'layer1.bias',\n",
       " 'layer2.weight',\n",
       " 'layer2.bias',\n",
       " 'layer3.weight',\n",
       " 'layer3.bias',\n",
       " 'output.weight',\n",
       " 'output.bias']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_params_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cce6d252",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_params_name = [name for name, param in model.state_dict(keep_vars=True).items()\n",
    "            if param.requires_grad ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69b3f86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['layer1.weight',\n",
       " 'layer1.bias',\n",
       " 'layer2.weight',\n",
       " 'layer2.bias',\n",
       " 'layer3.weight',\n",
       " 'layer3.bias',\n",
       " 'output.weight',\n",
       " 'output.bias']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainable_params_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a65af8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=model.state_dict()['layer1.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7990963a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 14])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e652714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1236,  0.0936, -0.0858,  ..., -0.2022,  0.2071,  0.2143],\n",
       "        [-0.0173, -0.0282,  0.0289,  ..., -0.0473,  0.0984, -0.1676],\n",
       "        [ 0.2257, -0.0810, -0.0682,  ..., -0.0027, -0.1340, -0.0711],\n",
       "        ...,\n",
       "        [-0.0892, -0.2357,  0.0203,  ...,  0.2679, -0.0388, -0.2460],\n",
       "        [ 0.2170,  0.2365,  0.2169,  ..., -0.1546,  0.0313,  0.2786],\n",
       "        [-0.0207, -0.1458, -0.1536,  ...,  0.0709, -0.0735, -0.1318]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['layer1.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66a8308a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_values([tensor([[-0.1236,  0.0936, -0.0858,  ..., -0.2022,  0.2071,  0.2143],\n",
       "        [-0.0173, -0.0282,  0.0289,  ..., -0.0473,  0.0984, -0.1676],\n",
       "        [ 0.2257, -0.0810, -0.0682,  ..., -0.0027, -0.1340, -0.0711],\n",
       "        ...,\n",
       "        [-0.0892, -0.2357,  0.0203,  ...,  0.2679, -0.0388, -0.2460],\n",
       "        [ 0.2170,  0.2365,  0.2169,  ..., -0.1546,  0.0313,  0.2786],\n",
       "        [-0.0207, -0.1458, -0.1536,  ...,  0.0709, -0.0735, -0.1318]]), tensor([-0.0322,  0.0426, -0.0603,  0.0798,  0.1138,  0.1408,  0.0317,  0.2289,\n",
       "         0.1325, -0.1165, -0.1265,  0.2285, -0.0939,  0.1958,  0.2569,  0.1675,\n",
       "        -0.2616,  0.1116,  0.1401, -0.0685, -0.1891, -0.1634, -0.1235,  0.0884,\n",
       "        -0.2367,  0.2376, -0.0763, -0.0003,  0.1408, -0.0229,  0.1229, -0.1721,\n",
       "         0.0450, -0.2093,  0.0882, -0.2293, -0.2588,  0.1078, -0.0765,  0.0842,\n",
       "        -0.0346, -0.0134, -0.2554,  0.0831, -0.1555,  0.0582,  0.1946, -0.2204,\n",
       "         0.2441,  0.1677, -0.0461, -0.1893,  0.2440,  0.1668, -0.0349, -0.1506,\n",
       "        -0.1688,  0.2263,  0.0252, -0.1341,  0.1226,  0.0148, -0.2670, -0.2387,\n",
       "        -0.1646,  0.0938,  0.2166, -0.1961,  0.2032,  0.2083, -0.0538, -0.1734,\n",
       "        -0.0966,  0.1707,  0.2654, -0.1752,  0.1697,  0.0705,  0.0117, -0.1214,\n",
       "        -0.0225,  0.2655,  0.0326, -0.2243,  0.0494,  0.0262,  0.1043, -0.2016,\n",
       "        -0.1868,  0.2294,  0.1924, -0.0286,  0.1204,  0.0552,  0.1580,  0.2101,\n",
       "         0.0064,  0.1496,  0.0149, -0.2476,  0.2136, -0.2267, -0.1353, -0.2492,\n",
       "        -0.0971,  0.0536,  0.0151, -0.1011, -0.1989,  0.1396, -0.0581, -0.0835,\n",
       "        -0.0924,  0.0628,  0.0724, -0.1092,  0.1702, -0.1673, -0.1401, -0.0940,\n",
       "         0.1129,  0.2617, -0.1878,  0.0058, -0.0888,  0.1451, -0.1095, -0.1658,\n",
       "        -0.0124,  0.0627, -0.1805, -0.2139,  0.1665, -0.2399,  0.1778,  0.0173,\n",
       "         0.2214, -0.2617,  0.1081, -0.1959,  0.0678, -0.0350,  0.1809, -0.1450,\n",
       "         0.2169, -0.1114,  0.1557,  0.0868, -0.0219, -0.0083, -0.1890, -0.0412,\n",
       "        -0.2220,  0.1934,  0.2318, -0.0247, -0.1509, -0.0488, -0.0465,  0.0737,\n",
       "        -0.2061, -0.2349,  0.2161,  0.2344,  0.2316, -0.1617,  0.0875,  0.0097,\n",
       "        -0.0420,  0.0644, -0.1184,  0.0654, -0.1385,  0.0454,  0.2524,  0.1664,\n",
       "         0.1929, -0.1204,  0.2308, -0.1499,  0.0881,  0.0181,  0.2450, -0.1845,\n",
       "         0.1118, -0.0929,  0.0865,  0.2135, -0.0189, -0.0089,  0.1641,  0.0661,\n",
       "         0.1976, -0.1441,  0.0790,  0.2366,  0.0260, -0.0965, -0.1012, -0.1548,\n",
       "         0.1602, -0.0468, -0.2533,  0.1919,  0.1327,  0.1548, -0.1613,  0.1136,\n",
       "         0.1652, -0.1754,  0.1503, -0.0373, -0.2608,  0.1419, -0.2441,  0.2094,\n",
       "        -0.2494,  0.0223, -0.2322,  0.0267, -0.1226, -0.0819,  0.0992, -0.0039,\n",
       "         0.1870, -0.0248,  0.2247,  0.0420, -0.1182, -0.1147,  0.0921, -0.0033,\n",
       "         0.2048,  0.1877, -0.1732, -0.0861,  0.2154,  0.0813, -0.0482, -0.1471,\n",
       "         0.0729,  0.1672, -0.2414,  0.1081, -0.0761, -0.1497, -0.0425,  0.0763,\n",
       "         0.0946, -0.1367,  0.0379, -0.0749, -0.2108,  0.0960,  0.0245,  0.2244,\n",
       "         0.1602, -0.2316, -0.0304, -0.1809, -0.0896,  0.2048,  0.2831,  0.2165,\n",
       "        -0.2307, -0.1157, -0.0104,  0.0336,  0.1026,  0.2040,  0.0713, -0.2639,\n",
       "         0.0778,  0.0500,  0.1923,  0.1277,  0.1815, -0.2308,  0.1551, -0.2286,\n",
       "        -0.2252, -0.0512,  0.2110,  0.0355, -0.1942,  0.1886, -0.1394,  0.0509,\n",
       "         0.1202, -0.1873, -0.0009, -0.0283,  0.2121,  0.0804,  0.1885,  0.2071,\n",
       "        -0.1146,  0.1334,  0.0909,  0.1458,  0.0371, -0.1957,  0.2245, -0.2641,\n",
       "        -0.0151, -0.0276, -0.0836, -0.1191, -0.0810,  0.1114, -0.1471, -0.0285,\n",
       "        -0.0704,  0.1866,  0.2525,  0.0854,  0.1541, -0.1246, -0.2074,  0.1898,\n",
       "         0.2544,  0.1057,  0.0266, -0.2380,  0.2070,  0.0359,  0.0576,  0.1031,\n",
       "         0.1448, -0.2236, -0.0662,  0.1450, -0.1213, -0.1980, -0.0199,  0.1476,\n",
       "         0.1931, -0.1353,  0.1945, -0.0050,  0.0417, -0.0790, -0.1385,  0.1613,\n",
       "         0.1442,  0.0873, -0.1752,  0.1793,  0.2524, -0.2422,  0.1832,  0.2125,\n",
       "         0.0878, -0.2427, -0.1157, -0.1772,  0.1735,  0.0131,  0.0559, -0.0500,\n",
       "        -0.1939, -0.1549,  0.1681,  0.2576,  0.0758,  0.0899,  0.0342, -0.0172,\n",
       "        -0.1564, -0.2578,  0.1180, -0.2498, -0.0539, -0.1182, -0.0336, -0.1141,\n",
       "         0.0446, -0.1486,  0.1746,  0.0762, -0.1405,  0.0448, -0.2609,  0.0096,\n",
       "        -0.0782,  0.2262,  0.2258, -0.0248,  0.0938, -0.2441, -0.0882,  0.0792,\n",
       "        -0.1055, -0.1155,  0.0341,  0.1175,  0.0215, -0.0857, -0.1695, -0.1577,\n",
       "        -0.1969,  0.1435, -0.2649,  0.1795, -0.1148,  0.2169,  0.0949, -0.2064,\n",
       "         0.0621, -0.1601,  0.2444, -0.0065,  0.1467,  0.0220,  0.0661,  0.1205,\n",
       "         0.0683, -0.1975,  0.0651,  0.2035,  0.1648, -0.2009, -0.2092, -0.2035,\n",
       "         0.0442,  0.2364, -0.2322, -0.1091, -0.1303, -0.0804, -0.1521,  0.0437,\n",
       "        -0.0293, -0.0676,  0.2063, -0.2415, -0.0775,  0.0658,  0.1934,  0.1241,\n",
       "         0.2322,  0.0168, -0.0104,  0.0872,  0.0879, -0.1017, -0.0718, -0.1307,\n",
       "         0.2594, -0.2004,  0.1750,  0.0769,  0.2043,  0.0724, -0.2261,  0.0856,\n",
       "        -0.1057, -0.2325,  0.1403,  0.0057,  0.1419,  0.0259,  0.1827, -0.0589,\n",
       "         0.0746, -0.0092, -0.0078, -0.1230,  0.1779,  0.1347, -0.0604,  0.1400,\n",
       "        -0.0195,  0.1195, -0.2178,  0.2222,  0.0282, -0.0979,  0.0141, -0.0208,\n",
       "         0.0783,  0.0834,  0.1010,  0.1194,  0.0306,  0.1227, -0.0238, -0.0877,\n",
       "        -0.1093,  0.0120,  0.2259,  0.1914, -0.1404,  0.1296, -0.1403,  0.1636,\n",
       "        -0.2438,  0.1688,  0.2359, -0.0039,  0.1959, -0.2448,  0.1091, -0.0898,\n",
       "        -0.0822, -0.1436, -0.0462,  0.1166, -0.1012,  0.2074,  0.0394,  0.0921]), tensor([[ 4.1278e-02, -6.7849e-03, -4.5960e-02,  ...,  6.2805e-05,\n",
       "         -2.6595e-02, -1.8976e-02],\n",
       "        [ 1.7838e-03, -2.4043e-02,  7.7809e-04,  ..., -7.5658e-02,\n",
       "          5.3687e-02, -8.9672e-03],\n",
       "        [ 1.0132e-02, -3.3095e-02, -2.9559e-02,  ..., -4.8992e-02,\n",
       "         -7.1659e-03,  2.1242e-02],\n",
       "        ...,\n",
       "        [-1.7378e-02, -8.9730e-03, -1.6638e-02,  ..., -2.5265e-02,\n",
       "          2.3593e-02,  1.8103e-02],\n",
       "        [ 3.5799e-02,  8.1830e-02,  2.2687e-03,  ...,  6.2357e-02,\n",
       "          1.8346e-02,  4.6302e-02],\n",
       "        [ 8.7989e-02,  4.6054e-02,  4.5712e-02,  ...,  2.1118e-02,\n",
       "         -5.3984e-02,  1.1680e-01]]), tensor([ 0.0384,  0.0524,  0.0343, -0.0506,  0.0003, -0.0071, -0.0294, -0.0185,\n",
       "         0.0118,  0.0057, -0.0228, -0.0090,  0.0057,  0.0404, -0.0217,  0.0036,\n",
       "        -0.0181,  0.0074, -0.0317, -0.0342,  0.0071, -0.0288, -0.0408,  0.0442,\n",
       "         0.0342, -0.0332, -0.0362,  0.0176, -0.0375,  0.0318,  0.0404,  0.0458,\n",
       "         0.0078,  0.0040,  0.0200, -0.0366,  0.0267, -0.0022,  0.0354, -0.0474,\n",
       "        -0.0166, -0.0006, -0.0007,  0.0400, -0.0372, -0.0399, -0.0033, -0.0008,\n",
       "         0.0100, -0.0250,  0.0383,  0.0199,  0.0128,  0.0305,  0.0343, -0.0221,\n",
       "         0.0687,  0.0022,  0.0105,  0.0151,  0.0002, -0.0363,  0.0017,  0.0028,\n",
       "         0.0230,  0.0226, -0.0056, -0.0060, -0.0110, -0.0195, -0.0237,  0.0310,\n",
       "         0.0229,  0.0102, -0.0455,  0.0325,  0.0163,  0.0451,  0.0147, -0.0333,\n",
       "        -0.0341, -0.0206, -0.0069,  0.0169,  0.0133, -0.0024, -0.0069, -0.0051,\n",
       "        -0.0018, -0.0373,  0.0120,  0.0156,  0.0120, -0.0171, -0.0177,  0.0141,\n",
       "        -0.0035, -0.0330, -0.0130, -0.0467, -0.0018,  0.0134, -0.0195, -0.0312,\n",
       "         0.0419,  0.0307,  0.0108, -0.0144,  0.0031,  0.0107, -0.0223,  0.0073,\n",
       "         0.0363, -0.0120, -0.0274, -0.0069,  0.0219,  0.0114, -0.0360,  0.0247,\n",
       "        -0.0016,  0.0057, -0.0445, -0.0320, -0.0266,  0.0085,  0.0428,  0.0379,\n",
       "        -0.0180,  0.0529,  0.0405, -0.0164,  0.0095, -0.0098,  0.0112,  0.0060,\n",
       "         0.0351, -0.0354,  0.0060, -0.0238, -0.0246,  0.0400,  0.0024,  0.0903,\n",
       "         0.0025,  0.0171, -0.0017, -0.0331, -0.0256,  0.0092, -0.0064, -0.0089,\n",
       "        -0.0344,  0.0494, -0.0250, -0.0384, -0.0258, -0.0120, -0.0347,  0.0508,\n",
       "        -0.0008, -0.0334, -0.0415,  0.0257,  0.0609,  0.0077, -0.0350, -0.0118,\n",
       "        -0.0241,  0.0029,  0.0233, -0.0546, -0.0086, -0.0486, -0.0328,  0.0228,\n",
       "        -0.0439, -0.0425, -0.0320,  0.0123, -0.0224,  0.0212, -0.0295,  0.0227,\n",
       "         0.0373,  0.0509, -0.0486,  0.0102,  0.0256,  0.0283, -0.0049,  0.0052,\n",
       "        -0.0157,  0.0483,  0.0189,  0.0068, -0.0114,  0.0213, -0.0225,  0.0361,\n",
       "        -0.0154, -0.0002,  0.0180, -0.0240,  0.0241,  0.0006,  0.0318, -0.0221,\n",
       "        -0.0064, -0.0498,  0.0070,  0.0372, -0.0281, -0.0068, -0.0252, -0.0090,\n",
       "         0.0113,  0.0234, -0.0158,  0.0324, -0.0249, -0.0172, -0.0205, -0.0013,\n",
       "         0.0095, -0.0057, -0.0430, -0.0238, -0.0108, -0.0365, -0.0168,  0.0380,\n",
       "        -0.0142,  0.0281, -0.0181,  0.0036,  0.0233,  0.0110,  0.0047,  0.0148,\n",
       "        -0.0202,  0.0722, -0.0015, -0.0202,  0.0105, -0.0281, -0.0308, -0.0169,\n",
       "         0.0263,  0.0244, -0.0248,  0.0092,  0.0101,  0.0149,  0.0076, -0.0055]), tensor([[ 5.4633e-02,  8.1261e-03, -3.0832e-02,  ...,  5.4763e-02,\n",
       "         -3.9070e-02, -4.7520e-02],\n",
       "        [ 7.2382e-02, -4.7307e-02, -2.3797e-02,  ...,  3.9055e-03,\n",
       "         -1.5235e-02, -1.7146e-02],\n",
       "        [-1.7924e-02,  4.6757e-04, -4.0349e-02,  ...,  5.7521e-02,\n",
       "          9.0531e-02, -2.5051e-03],\n",
       "        ...,\n",
       "        [ 1.4053e-02, -4.3309e-02,  3.2839e-05,  ..., -2.4532e-02,\n",
       "         -2.0915e-02,  6.3625e-02],\n",
       "        [-5.1204e-03,  4.1185e-02,  1.7763e-02,  ...,  2.1898e-03,\n",
       "         -7.2193e-02,  1.9890e-02],\n",
       "        [-5.4119e-02,  2.7216e-02, -4.5889e-02,  ...,  1.9468e-03,\n",
       "          1.6108e-02,  3.3428e-02]]), tensor([ 0.0218,  0.0122, -0.0090,  0.0192,  0.0073, -0.0146, -0.0172, -0.0161,\n",
       "         0.0034, -0.0175, -0.0405,  0.0299, -0.0603, -0.0260,  0.0148, -0.0506,\n",
       "         0.0101,  0.0233,  0.0611,  0.0053,  0.0120,  0.0282, -0.0101, -0.0045,\n",
       "         0.0508,  0.0130, -0.0003, -0.0131, -0.0401,  0.0463, -0.0210,  0.0293,\n",
       "        -0.0256,  0.0346,  0.0168, -0.0242, -0.0049, -0.0485,  0.0420,  0.0150,\n",
       "         0.0399, -0.0609, -0.0609,  0.0046,  0.0419, -0.0323, -0.0594,  0.0583,\n",
       "        -0.0254, -0.0278,  0.0016, -0.0256, -0.0305,  0.0366, -0.0453,  0.0189,\n",
       "        -0.0292,  0.0077,  0.0030, -0.0285]), tensor([[ 0.0554, -0.0423, -0.1156,  0.0730, -0.0532,  0.0089, -0.0901, -0.1038,\n",
       "         -0.1392,  0.0981,  0.0516,  0.1187, -0.0476, -0.1402,  0.0835,  0.0997,\n",
       "         -0.1758,  0.1161,  0.1730,  0.0904, -0.0909,  0.0716, -0.0481, -0.0731,\n",
       "         -0.1037, -0.0566, -0.0789,  0.0637,  0.0840, -0.0526,  0.0498,  0.0710,\n",
       "         -0.0173,  0.0521, -0.0801,  0.1083, -0.1271,  0.0110,  0.1764, -0.1537,\n",
       "         -0.1162, -0.0945, -0.1474,  0.1394,  0.0944,  0.0190,  0.0964, -0.1173,\n",
       "         -0.1240,  0.1212,  0.1095, -0.0452,  0.0376, -0.1081, -0.0215, -0.1443,\n",
       "          0.0689, -0.1461,  0.1446, -0.0005]]), tensor([-0.0053])])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict().values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13f0aaa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1236],\n",
       "         [ 0.0936],\n",
       "         [-0.0858],\n",
       "         ...,\n",
       "         [-0.2022],\n",
       "         [ 0.2071],\n",
       "         [ 0.2143]],\n",
       "\n",
       "        [[-0.0173],\n",
       "         [-0.0282],\n",
       "         [ 0.0289],\n",
       "         ...,\n",
       "         [-0.0473],\n",
       "         [ 0.0984],\n",
       "         [-0.1676]],\n",
       "\n",
       "        [[ 0.2257],\n",
       "         [-0.0810],\n",
       "         [-0.0682],\n",
       "         ...,\n",
       "         [-0.0027],\n",
       "         [-0.1340],\n",
       "         [-0.0711]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0892],\n",
       "         [-0.2357],\n",
       "         [ 0.0203],\n",
       "         ...,\n",
       "         [ 0.2679],\n",
       "         [-0.0388],\n",
       "         [-0.2460]],\n",
       "\n",
       "        [[ 0.2170],\n",
       "         [ 0.2365],\n",
       "         [ 0.2169],\n",
       "         ...,\n",
       "         [-0.1546],\n",
       "         [ 0.0313],\n",
       "         [ 0.2786]],\n",
       "\n",
       "        [[-0.0207],\n",
       "         [-0.1458],\n",
       "         [-0.1536],\n",
       "         ...,\n",
       "         [ 0.0709],\n",
       "         [-0.0735],\n",
       "         [-0.1318]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(( model.state_dict()['layer1.weight'],), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f1c4465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 14])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a/a.sum()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2811a436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(108.5115)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(a/(a.sum()*torch.stack(( model.state_dict()['layer1.weight'],))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f67c2e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.1236,  0.0936, -0.0858,  ..., -0.2022,  0.2071,  0.2143],\n",
       "         [-0.0173, -0.0282,  0.0289,  ..., -0.0473,  0.0984, -0.1676],\n",
       "         [ 0.2257, -0.0810, -0.0682,  ..., -0.0027, -0.1340, -0.0711],\n",
       "         ...,\n",
       "         [-0.0892, -0.2357,  0.0203,  ...,  0.2679, -0.0388, -0.2460],\n",
       "         [ 0.2170,  0.2365,  0.2169,  ..., -0.1546,  0.0313,  0.2786],\n",
       "         [-0.0207, -0.1458, -0.1536,  ...,  0.0709, -0.0735, -0.1318]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0322,  0.0426, -0.0603,  0.0798,  0.1138,  0.1408,  0.0317,  0.2289,\n",
       "          0.1325, -0.1165, -0.1265,  0.2285, -0.0939,  0.1958,  0.2569,  0.1675,\n",
       "         -0.2616,  0.1116,  0.1401, -0.0685, -0.1891, -0.1634, -0.1235,  0.0884,\n",
       "         -0.2367,  0.2376, -0.0763, -0.0003,  0.1408, -0.0229,  0.1229, -0.1721,\n",
       "          0.0450, -0.2093,  0.0882, -0.2293, -0.2588,  0.1078, -0.0765,  0.0842,\n",
       "         -0.0346, -0.0134, -0.2554,  0.0831, -0.1555,  0.0582,  0.1946, -0.2204,\n",
       "          0.2441,  0.1677, -0.0461, -0.1893,  0.2440,  0.1668, -0.0349, -0.1506,\n",
       "         -0.1688,  0.2263,  0.0252, -0.1341,  0.1226,  0.0148, -0.2670, -0.2387,\n",
       "         -0.1646,  0.0938,  0.2166, -0.1961,  0.2032,  0.2083, -0.0538, -0.1734,\n",
       "         -0.0966,  0.1707,  0.2654, -0.1752,  0.1697,  0.0705,  0.0117, -0.1214,\n",
       "         -0.0225,  0.2655,  0.0326, -0.2243,  0.0494,  0.0262,  0.1043, -0.2016,\n",
       "         -0.1868,  0.2294,  0.1924, -0.0286,  0.1204,  0.0552,  0.1580,  0.2101,\n",
       "          0.0064,  0.1496,  0.0149, -0.2476,  0.2136, -0.2267, -0.1353, -0.2492,\n",
       "         -0.0971,  0.0536,  0.0151, -0.1011, -0.1989,  0.1396, -0.0581, -0.0835,\n",
       "         -0.0924,  0.0628,  0.0724, -0.1092,  0.1702, -0.1673, -0.1401, -0.0940,\n",
       "          0.1129,  0.2617, -0.1878,  0.0058, -0.0888,  0.1451, -0.1095, -0.1658,\n",
       "         -0.0124,  0.0627, -0.1805, -0.2139,  0.1665, -0.2399,  0.1778,  0.0173,\n",
       "          0.2214, -0.2617,  0.1081, -0.1959,  0.0678, -0.0350,  0.1809, -0.1450,\n",
       "          0.2169, -0.1114,  0.1557,  0.0868, -0.0219, -0.0083, -0.1890, -0.0412,\n",
       "         -0.2220,  0.1934,  0.2318, -0.0247, -0.1509, -0.0488, -0.0465,  0.0737,\n",
       "         -0.2061, -0.2349,  0.2161,  0.2344,  0.2316, -0.1617,  0.0875,  0.0097,\n",
       "         -0.0420,  0.0644, -0.1184,  0.0654, -0.1385,  0.0454,  0.2524,  0.1664,\n",
       "          0.1929, -0.1204,  0.2308, -0.1499,  0.0881,  0.0181,  0.2450, -0.1845,\n",
       "          0.1118, -0.0929,  0.0865,  0.2135, -0.0189, -0.0089,  0.1641,  0.0661,\n",
       "          0.1976, -0.1441,  0.0790,  0.2366,  0.0260, -0.0965, -0.1012, -0.1548,\n",
       "          0.1602, -0.0468, -0.2533,  0.1919,  0.1327,  0.1548, -0.1613,  0.1136,\n",
       "          0.1652, -0.1754,  0.1503, -0.0373, -0.2608,  0.1419, -0.2441,  0.2094,\n",
       "         -0.2494,  0.0223, -0.2322,  0.0267, -0.1226, -0.0819,  0.0992, -0.0039,\n",
       "          0.1870, -0.0248,  0.2247,  0.0420, -0.1182, -0.1147,  0.0921, -0.0033,\n",
       "          0.2048,  0.1877, -0.1732, -0.0861,  0.2154,  0.0813, -0.0482, -0.1471,\n",
       "          0.0729,  0.1672, -0.2414,  0.1081, -0.0761, -0.1497, -0.0425,  0.0763,\n",
       "          0.0946, -0.1367,  0.0379, -0.0749, -0.2108,  0.0960,  0.0245,  0.2244,\n",
       "          0.1602, -0.2316, -0.0304, -0.1809, -0.0896,  0.2048,  0.2831,  0.2165,\n",
       "         -0.2307, -0.1157, -0.0104,  0.0336,  0.1026,  0.2040,  0.0713, -0.2639,\n",
       "          0.0778,  0.0500,  0.1923,  0.1277,  0.1815, -0.2308,  0.1551, -0.2286,\n",
       "         -0.2252, -0.0512,  0.2110,  0.0355, -0.1942,  0.1886, -0.1394,  0.0509,\n",
       "          0.1202, -0.1873, -0.0009, -0.0283,  0.2121,  0.0804,  0.1885,  0.2071,\n",
       "         -0.1146,  0.1334,  0.0909,  0.1458,  0.0371, -0.1957,  0.2245, -0.2641,\n",
       "         -0.0151, -0.0276, -0.0836, -0.1191, -0.0810,  0.1114, -0.1471, -0.0285,\n",
       "         -0.0704,  0.1866,  0.2525,  0.0854,  0.1541, -0.1246, -0.2074,  0.1898,\n",
       "          0.2544,  0.1057,  0.0266, -0.2380,  0.2070,  0.0359,  0.0576,  0.1031,\n",
       "          0.1448, -0.2236, -0.0662,  0.1450, -0.1213, -0.1980, -0.0199,  0.1476,\n",
       "          0.1931, -0.1353,  0.1945, -0.0050,  0.0417, -0.0790, -0.1385,  0.1613,\n",
       "          0.1442,  0.0873, -0.1752,  0.1793,  0.2524, -0.2422,  0.1832,  0.2125,\n",
       "          0.0878, -0.2427, -0.1157, -0.1772,  0.1735,  0.0131,  0.0559, -0.0500,\n",
       "         -0.1939, -0.1549,  0.1681,  0.2576,  0.0758,  0.0899,  0.0342, -0.0172,\n",
       "         -0.1564, -0.2578,  0.1180, -0.2498, -0.0539, -0.1182, -0.0336, -0.1141,\n",
       "          0.0446, -0.1486,  0.1746,  0.0762, -0.1405,  0.0448, -0.2609,  0.0096,\n",
       "         -0.0782,  0.2262,  0.2258, -0.0248,  0.0938, -0.2441, -0.0882,  0.0792,\n",
       "         -0.1055, -0.1155,  0.0341,  0.1175,  0.0215, -0.0857, -0.1695, -0.1577,\n",
       "         -0.1969,  0.1435, -0.2649,  0.1795, -0.1148,  0.2169,  0.0949, -0.2064,\n",
       "          0.0621, -0.1601,  0.2444, -0.0065,  0.1467,  0.0220,  0.0661,  0.1205,\n",
       "          0.0683, -0.1975,  0.0651,  0.2035,  0.1648, -0.2009, -0.2092, -0.2035,\n",
       "          0.0442,  0.2364, -0.2322, -0.1091, -0.1303, -0.0804, -0.1521,  0.0437,\n",
       "         -0.0293, -0.0676,  0.2063, -0.2415, -0.0775,  0.0658,  0.1934,  0.1241,\n",
       "          0.2322,  0.0168, -0.0104,  0.0872,  0.0879, -0.1017, -0.0718, -0.1307,\n",
       "          0.2594, -0.2004,  0.1750,  0.0769,  0.2043,  0.0724, -0.2261,  0.0856,\n",
       "         -0.1057, -0.2325,  0.1403,  0.0057,  0.1419,  0.0259,  0.1827, -0.0589,\n",
       "          0.0746, -0.0092, -0.0078, -0.1230,  0.1779,  0.1347, -0.0604,  0.1400,\n",
       "         -0.0195,  0.1195, -0.2178,  0.2222,  0.0282, -0.0979,  0.0141, -0.0208,\n",
       "          0.0783,  0.0834,  0.1010,  0.1194,  0.0306,  0.1227, -0.0238, -0.0877,\n",
       "         -0.1093,  0.0120,  0.2259,  0.1914, -0.1404,  0.1296, -0.1403,  0.1636,\n",
       "         -0.2438,  0.1688,  0.2359, -0.0039,  0.1959, -0.2448,  0.1091, -0.0898,\n",
       "         -0.0822, -0.1436, -0.0462,  0.1166, -0.1012,  0.2074,  0.0394,  0.0921],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 4.1278e-02, -6.7849e-03, -4.5960e-02,  ...,  6.2805e-05,\n",
       "          -2.6595e-02, -1.8976e-02],\n",
       "         [ 1.7838e-03, -2.4043e-02,  7.7809e-04,  ..., -7.5658e-02,\n",
       "           5.3687e-02, -8.9672e-03],\n",
       "         [ 1.0132e-02, -3.3095e-02, -2.9559e-02,  ..., -4.8992e-02,\n",
       "          -7.1659e-03,  2.1242e-02],\n",
       "         ...,\n",
       "         [-1.7378e-02, -8.9730e-03, -1.6638e-02,  ..., -2.5265e-02,\n",
       "           2.3593e-02,  1.8103e-02],\n",
       "         [ 3.5799e-02,  8.1830e-02,  2.2687e-03,  ...,  6.2357e-02,\n",
       "           1.8346e-02,  4.6302e-02],\n",
       "         [ 8.7989e-02,  4.6054e-02,  4.5712e-02,  ...,  2.1118e-02,\n",
       "          -5.3984e-02,  1.1680e-01]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0384,  0.0524,  0.0343, -0.0506,  0.0003, -0.0071, -0.0294, -0.0185,\n",
       "          0.0118,  0.0057, -0.0228, -0.0090,  0.0057,  0.0404, -0.0217,  0.0036,\n",
       "         -0.0181,  0.0074, -0.0317, -0.0342,  0.0071, -0.0288, -0.0408,  0.0442,\n",
       "          0.0342, -0.0332, -0.0362,  0.0176, -0.0375,  0.0318,  0.0404,  0.0458,\n",
       "          0.0078,  0.0040,  0.0200, -0.0366,  0.0267, -0.0022,  0.0354, -0.0474,\n",
       "         -0.0166, -0.0006, -0.0007,  0.0400, -0.0372, -0.0399, -0.0033, -0.0008,\n",
       "          0.0100, -0.0250,  0.0383,  0.0199,  0.0128,  0.0305,  0.0343, -0.0221,\n",
       "          0.0687,  0.0022,  0.0105,  0.0151,  0.0002, -0.0363,  0.0017,  0.0028,\n",
       "          0.0230,  0.0226, -0.0056, -0.0060, -0.0110, -0.0195, -0.0237,  0.0310,\n",
       "          0.0229,  0.0102, -0.0455,  0.0325,  0.0163,  0.0451,  0.0147, -0.0333,\n",
       "         -0.0341, -0.0206, -0.0069,  0.0169,  0.0133, -0.0024, -0.0069, -0.0051,\n",
       "         -0.0018, -0.0373,  0.0120,  0.0156,  0.0120, -0.0171, -0.0177,  0.0141,\n",
       "         -0.0035, -0.0330, -0.0130, -0.0467, -0.0018,  0.0134, -0.0195, -0.0312,\n",
       "          0.0419,  0.0307,  0.0108, -0.0144,  0.0031,  0.0107, -0.0223,  0.0073,\n",
       "          0.0363, -0.0120, -0.0274, -0.0069,  0.0219,  0.0114, -0.0360,  0.0247,\n",
       "         -0.0016,  0.0057, -0.0445, -0.0320, -0.0266,  0.0085,  0.0428,  0.0379,\n",
       "         -0.0180,  0.0529,  0.0405, -0.0164,  0.0095, -0.0098,  0.0112,  0.0060,\n",
       "          0.0351, -0.0354,  0.0060, -0.0238, -0.0246,  0.0400,  0.0024,  0.0903,\n",
       "          0.0025,  0.0171, -0.0017, -0.0331, -0.0256,  0.0092, -0.0064, -0.0089,\n",
       "         -0.0344,  0.0494, -0.0250, -0.0384, -0.0258, -0.0120, -0.0347,  0.0508,\n",
       "         -0.0008, -0.0334, -0.0415,  0.0257,  0.0609,  0.0077, -0.0350, -0.0118,\n",
       "         -0.0241,  0.0029,  0.0233, -0.0546, -0.0086, -0.0486, -0.0328,  0.0228,\n",
       "         -0.0439, -0.0425, -0.0320,  0.0123, -0.0224,  0.0212, -0.0295,  0.0227,\n",
       "          0.0373,  0.0509, -0.0486,  0.0102,  0.0256,  0.0283, -0.0049,  0.0052,\n",
       "         -0.0157,  0.0483,  0.0189,  0.0068, -0.0114,  0.0213, -0.0225,  0.0361,\n",
       "         -0.0154, -0.0002,  0.0180, -0.0240,  0.0241,  0.0006,  0.0318, -0.0221,\n",
       "         -0.0064, -0.0498,  0.0070,  0.0372, -0.0281, -0.0068, -0.0252, -0.0090,\n",
       "          0.0113,  0.0234, -0.0158,  0.0324, -0.0249, -0.0172, -0.0205, -0.0013,\n",
       "          0.0095, -0.0057, -0.0430, -0.0238, -0.0108, -0.0365, -0.0168,  0.0380,\n",
       "         -0.0142,  0.0281, -0.0181,  0.0036,  0.0233,  0.0110,  0.0047,  0.0148,\n",
       "         -0.0202,  0.0722, -0.0015, -0.0202,  0.0105, -0.0281, -0.0308, -0.0169,\n",
       "          0.0263,  0.0244, -0.0248,  0.0092,  0.0101,  0.0149,  0.0076, -0.0055],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 5.4633e-02,  8.1261e-03, -3.0832e-02,  ...,  5.4763e-02,\n",
       "          -3.9070e-02, -4.7520e-02],\n",
       "         [ 7.2382e-02, -4.7307e-02, -2.3797e-02,  ...,  3.9055e-03,\n",
       "          -1.5235e-02, -1.7146e-02],\n",
       "         [-1.7924e-02,  4.6757e-04, -4.0349e-02,  ...,  5.7521e-02,\n",
       "           9.0531e-02, -2.5051e-03],\n",
       "         ...,\n",
       "         [ 1.4053e-02, -4.3309e-02,  3.2839e-05,  ..., -2.4532e-02,\n",
       "          -2.0915e-02,  6.3625e-02],\n",
       "         [-5.1204e-03,  4.1185e-02,  1.7763e-02,  ...,  2.1898e-03,\n",
       "          -7.2193e-02,  1.9890e-02],\n",
       "         [-5.4119e-02,  2.7216e-02, -4.5889e-02,  ...,  1.9468e-03,\n",
       "           1.6108e-02,  3.3428e-02]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0218,  0.0122, -0.0090,  0.0192,  0.0073, -0.0146, -0.0172, -0.0161,\n",
       "          0.0034, -0.0175, -0.0405,  0.0299, -0.0603, -0.0260,  0.0148, -0.0506,\n",
       "          0.0101,  0.0233,  0.0611,  0.0053,  0.0120,  0.0282, -0.0101, -0.0045,\n",
       "          0.0508,  0.0130, -0.0003, -0.0131, -0.0401,  0.0463, -0.0210,  0.0293,\n",
       "         -0.0256,  0.0346,  0.0168, -0.0242, -0.0049, -0.0485,  0.0420,  0.0150,\n",
       "          0.0399, -0.0609, -0.0609,  0.0046,  0.0419, -0.0323, -0.0594,  0.0583,\n",
       "         -0.0254, -0.0278,  0.0016, -0.0256, -0.0305,  0.0366, -0.0453,  0.0189,\n",
       "         -0.0292,  0.0077,  0.0030, -0.0285], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0554, -0.0423, -0.1156,  0.0730, -0.0532,  0.0089, -0.0901, -0.1038,\n",
       "          -0.1392,  0.0981,  0.0516,  0.1187, -0.0476, -0.1402,  0.0835,  0.0997,\n",
       "          -0.1758,  0.1161,  0.1730,  0.0904, -0.0909,  0.0716, -0.0481, -0.0731,\n",
       "          -0.1037, -0.0566, -0.0789,  0.0637,  0.0840, -0.0526,  0.0498,  0.0710,\n",
       "          -0.0173,  0.0521, -0.0801,  0.1083, -0.1271,  0.0110,  0.1764, -0.1537,\n",
       "          -0.1162, -0.0945, -0.1474,  0.1394,  0.0944,  0.0190,  0.0964, -0.1173,\n",
       "          -0.1240,  0.1212,  0.1095, -0.0452,  0.0376, -0.1081, -0.0215, -0.1443,\n",
       "           0.0689, -0.1461,  0.1446, -0.0005]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0053], requires_grad=True)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLP\n",
    "\n",
    "list(filter(lambda p: p.requires_grad,model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51b00e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x0000026F56F60E40>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eddbf1e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (512) must match the size of tensor b (14) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m torch\u001b[38;5;241m.\u001b[39msum(\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlayer1.weight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (512) must match the size of tensor b (14) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "torch.sum(a / a.sum() * torch.stack((model.state_dict()['layer1.weight'],), dim=-1), dim=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "07819d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of a: torch.Size([512, 14])\n",
      "Shape of layer1.weight: torch.Size([512, 14])\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of a:\", a.shape)\n",
    "print(\"Shape of layer1.weight:\", model.state_dict()['layer1.weight'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c1b4ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49b9f60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d16d19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17a47b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08d50d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5659372",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
